# Neural Network from Scratch with NumPy

```


This repository contains a Python implementation of a basic neural network from scratch using only NumPy. The network is trained and tested on the MNIST dataset for handwritten digit classification.

## Overview

This project demonstrates the implementation of a neural network without relying on deep learning libraries like TensorFlow or PyTorch. The network architecture includes one hidden layer with ReLU activation and an output layer with softmax activation. The training process involves forward and backward propagation to update the network parameters (weights and biases).

## Usage

1. **Clone the Repository**: 
   ```
   git clone https://github.com/akshaiyan-b/Number-recognition-from-scratch.git
   ```

2. **Install Dependencies**: 
   Ensure you have Python 3.x installed along with NumPy.
   ```
   pip install numpy
   ```

3. **Run the Code**: 
   Execute the main script `neural_network.py` to train and test the neural network.
   ```
   python neural_network.py
   ```

4. **Customization**: 
   Feel free to experiment with the network architecture, hyperparameters, and training process to adapt it to different datasets or improve performance.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Acknowledgments

- Special thanks to the creators of the MNIST dataset for providing a valuable benchmark dataset for machine learning research and education.
```

This README provides a brief overview of the project, instructions for usage, and acknowledgments. Feel free to customize it further according to your preferences and project specifics.
